{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4ab2b79-bb80-4bd8-83f6-bcfe5d1f16ab",
   "metadata": {},
   "source": [
    "#Question 1 Transpose a Matrix using MapReduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c0b9484-76e9-43ed-8444-5cfeb6bdc23b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2\n",
       "0  0  0  1\n",
       "1  0  1  2\n",
       "2  1  1  3\n",
       "3  1  0  4"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read the text file example matrix\n",
    "og_matrix = pd.read_csv('matrix.txt', delimiter=',', header=None)\n",
    "og_matrix\n",
    "\n",
    "#MAPPER.PY\n",
    "#read each line of og_matrix in the format (i, j, v)\n",
    "# Map into (j, (i, v))\n",
    "#where i = row, j = column, v = value\n",
    "#column becomes the key\n",
    "\n",
    "#Intermediate key,value pairs from matrix will be\n",
    "#(0, (0, 1)), (1, (0, 2)), (1, (1, 3)), (0, (1, 4))\n",
    "\n",
    "#REDUCER.PY\n",
    "#GROUP BY KEY\n",
    "#(0, (0, 1), (1, 4)), (1, (0, 2), (1, 3))\n",
    "#Combine key with the new value pair\n",
    "\n",
    "#Combine column and row to create new coordinates, which provides the output in the format row, column, value. With the row and column swapped.\n",
    "#0, 0, 1\n",
    "#0, 1, 4\n",
    "#1, 0, 2\n",
    "#1, 1, 3\n",
    "\n",
    "#HADOOP COMMAND\n",
    "!hadoop jar /opt/hadoop-3.2.1/share/hadoop/tools/lib/hadoop-streaming-3.2.1.jar \\\n",
    "    -file $PWD/Q1_mapper.py\\\n",
    "    -file $PWD/Q1_reducer.py\\\n",
    "    -mapper Q1_mapper.py \\\n",
    "    -reducer Q1_reducer.py \\\n",
    "    -input A2/Q1/inputs/ \\\n",
    "    -output A2/Q1/outputs/result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11fbdaf2-40ec-4bc3-8ea4-6ca0daf3d583",
   "metadata": {},
   "source": [
    "#QUESTION 2 - Parallel Breadth First Search Using MapReduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18c5d438-bbbb-4247-844e-960ce8e6d85c",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m<tokenize>:9\u001b[0;36m\u001b[0m\n\u001b[0;31m    elif CurrentNode.color == Black\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "#Read the input graph in the format source<tab>adjacency_list|distance_from_the_source|color|parentNode, with each node on a new line\n",
    "\n",
    "#MAPPER.PY\n",
    "each node can be sent to a different computer, all reduced at the end\n",
    "Loop through entire input reading line by line\n",
    "If CurrentNode.color == White\n",
    "    emit entire line\n",
    "    \n",
    " elif CurrentNode.color == Black\n",
    "    emit entire line\n",
    "    \n",
    "elif CurrentNode.color == Grey\n",
    "    CurrentNode.color = Black\n",
    "    \n",
    "    for all nodes in CurrentNode.adjacency_list\n",
    "        ParentNode = CurrentNode\n",
    "        color = Grey\n",
    "        score = CurrentNode.score + 1\n",
    "        adjacency_list = null\n",
    "        emit child node line\n",
    "        \n",
    "#Intermediate values after first mapping iteration\n",
    "1<tab>2,3|0|BLACK|0\n",
    "2<tab>1,3,4,5|Integer.MAX_VALUE|WHITE|null\n",
    "3<tab>1,4,2|Integer.MAX_VALUE|WHITE|null\n",
    "\n",
    "2<tab>null|1|GRAY|1\n",
    "3<tab>null|1|GRAY|1\n",
    "\n",
    "4<tab>2,3|Integer.MAX_VALUE|WHITE|null\n",
    "5<tab>2|Integer.MAX_VALUE|WHITE|null\n",
    "        \n",
    "#REDUCER.PY\n",
    "for all nodes emitted:\n",
    "    combine on source nodes\n",
    "         score = min of all scores occuring for source\n",
    "        colour = keep darkest colour to occur\n",
    "        adjacency_list maintain the non_null list that was emitted\n",
    "\n",
    "#Intermediate values after first reduction iteration\n",
    "1<tab>2,3|0|BLACK|0\n",
    "2<tab>1,3,4,5|Integer.MAX_VALUE|GRAY|1\n",
    "3<tab>1,4,2|Integer.MAX_VALUE|GRAY|1\n",
    "4<tab>2,3|Integer.MAX_VALUE|WHITE|null\n",
    "5<tab>2|Integer.MAX_VALUE|WHITE|null\n",
    "\n",
    "#With each iteration, one node turns black\n",
    "#Therefore need 5 iterations to fully complete traversal of the graph\n",
    "\n",
    "!hadoop jar /opt/hadoop-3.2.1/share/hadoop/tools/lib/hadoop-streaming-3.2.1.jar \\\n",
    "    -file $PWD/Q2_mapper.py\\\n",
    "    -file $PWD/Q2_reducer.py\\\n",
    "    -mapper Q2_mapper.py \\\n",
    "    -reducer Q2_reducer.py \\\n",
    "    -input A2/Q2/inputs/ \\\n",
    "    -output A2/Q2/outputs/result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659a0074-d561-4517-b49a-b3c04368224d",
   "metadata": {},
   "source": [
    "#QUESTION 3 - Normalized Word Co-occurence Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33f5ff6-1786-4160-93b9-3d0368947e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Uses the keyfieldpartitioner '.' to separate items\n",
    "\n",
    "#MAPPER.PY\n",
    "Use '.' to format keys in K1.K2:V\n",
    "#K1 = current grocery item\n",
    "#K2 = other grocery item in the same line\n",
    "#V = value\n",
    "\n",
    "for each line:\n",
    "    for k1 in line:\n",
    "        for k2 != k1 in line:\n",
    "            emit (k1.k2.1)\n",
    "\n",
    "Intermediate Key value pairs will be as shown below:\n",
    "\n",
    "cheese.bread.1; cheese.milk.1; bread.cheese.1; bread.milk.1; milk.cheese.1; milk.bread.1; \n",
    "candy.milk.1; candy.coke.1; milk.candy.1; milk.coke.1; coke.candy.1; coke.milk.1; \n",
    "milk.coffee.1; milk.eggs.1; milk.cheese.1; coffee.milk.1; coffee.eggs.1; coffee.cheese.1; eggs.milk.1; eggs.coffee.1; eggs.cheese.1;  cheese.milk.1; cheese.coffee.1; cheese.eggs.1; \n",
    "\n",
    "#REDUCER.PY\n",
    "reduce based on k1 and k2\n",
    "visited = [] #so we don't visit the same k1.k2 pairs twice\n",
    "reduced_pairs = [] #create an empty list to store k1.k2.v, where value is the reduced number of occurences of k1.k2\n",
    "reduced_k1 = [] #create array of only k1 values and their repetitions\n",
    "\n",
    "#make sure to not visit values that were already reduced once\n",
    "for i in list AND i NOT in visited:\n",
    "    count_pairs = 1 #reset the count to 1, since if the k1.k2 pair was listed then it occured at least once\n",
    "    count_k1 = 1\n",
    "    \n",
    "    for j != i in list:\n",
    "        \n",
    "        if i.k1.k2 == j.k1.k2: #if there is a repetition of k1.k2 both\n",
    "            visited.append(i.k1.k2) #append to the visited list, so we don't double count\n",
    "            count_pairs += 1 #increment the count for the pairs\n",
    "            count_k1 += 1 #incremement count for k1 specifically\n",
    "            \n",
    "        elif i.k1 == i.k2:\n",
    "            count_k1 += 1\n",
    "            \n",
    "    reduced_pairs.append(i.k1.k2.count_pairs) #append the k1.k2 value pair, along with the number of times it repeated (count)\n",
    "    reduced_k1.append(i.k1.count_k1)\n",
    "\n",
    "After reducer stage, two lists are created\n",
    "\n",
    "Reduced pairs will be:\n",
    "    \n",
    "cheese.bread.1; cheese.milk.2; bread.cheese.1; bread.milk.1; milk.cheese.2; milk.bread.1; \n",
    "candy.milk.1; candy.coke.1; milk.candy.1; milk.coke.1; coke.candy.1; coke.milk.1; \n",
    "milk.coffee.1; milk.eggs.1; coffee.milk.1; coffee.eggs.1; coffee.cheese.1; eggs.milk.1; eggs.coffee.1; eggs.cheese.1; cheese.coffee.1; cheese.eggs.1;\n",
    "    \n",
    "reduced_k1 will be:\n",
    "[cheese, 1; bread, 2; milk, 7; candy, 2; coffee, 3; eggs, 3]\n",
    "\n",
    "#example command to call hadoop map reducer using multiple keys, field separator = '.'\n",
    "\n",
    "\n",
    "!hadoop jar /opt/hadoop-3.2.1/share/hadoop/tools/lib/hadoop-streaming-3.2.1.jar \\\n",
    "    -D mapred.reduce.tasks=1 \\\n",
    "    -D stream.map.output.field.separator=. \\\n",
    "    -D stream.num.map.output.key.fields=3 \\\n",
    "    -D map.output.key.field.separator=. \\\n",
    "    -D mapred.text.key.partitioner.options=k1.k2.1 \\\n",
    "    -partitioner org.apache.hadoop.mapred.lib.KeyFieldBasedPartitioner \\\n",
    "    -file $PWD/Q3_mapper.py\\\n",
    "    -file $PWD/Q3_reducer.py\\\n",
    "    -mapper Q3_mapper.py \\\n",
    "    -reducer Q._reducer.py \\\n",
    "    -input A2/Q3/inputs/ \\\n",
    "    -output A2/Q3/outputs/result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
