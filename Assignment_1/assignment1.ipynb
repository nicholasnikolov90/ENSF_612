{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "949caba9-01b5-4478-8a70-c149340a3c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ab2b79-bb80-4bd8-83f6-bcfe5d1f16ab",
   "metadata": {},
   "source": [
    "#Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c0b9484-76e9-43ed-8444-5cfeb6bdc23b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             0\n",
      "8       Drive,\n",
      "59         was\n",
      "92        came\n",
      "104    craning\n",
      "97         she\n",
      "30          be\n",
      "44   nonsense.\n",
      "33    anything\n",
      "63         man\n",
      "26      people\n",
      "73        very\n",
      "7       Privet\n",
      "22        They\n"
     ]
    }
   ],
   "source": [
    "#read the text file\n",
    "text = pd.read_csv('harryPotter.txt', delimiter=' ', header=None)\n",
    "text=text.T\n",
    "\n",
    "#randomly sample 10% of the rows\n",
    "sampled_text = text.sample(frac=0.10, random_state = 0)\n",
    "print(sampled_text) #print 10% sampled\n",
    "\n",
    "#pseudocode to write into the HDFS\n",
    "#for i in sampled_text:\n",
    "#    write into HDFS\n",
    "\n",
    "#example Hadoop streaming command to write into the HDFS\n",
    "#$HADOOP_HOME/bin/hadoop jar $HADOOP_HOME/hadoop-streaming.jar \\\n",
    "#-files assignment1.py -mapper /bin/cat -reducer assignment1.py \\\n",
    "#-input haryyPotter.txt -output hdfs_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11fbdaf2-40ec-4bc3-8ea4-6ca0daf3d583",
   "metadata": {},
   "source": [
    "#QUESTION 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "18c5d438-bbbb-4247-844e-960ce8e6d85c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0         1  2              3\n",
      "0         mr       and  1          a had\n",
      "1        and       mrs  1         a have\n",
      "2        mrs   dursley  1           a of\n",
      "3    dursley        of  1          a was\n",
      "4         of    number  1  although neck\n",
      "..       ...       ... ..            ...\n",
      "124    there       was  1     which neck\n",
      "125      was        no  1      with hold\n",
      "126       no     finer  1       with man\n",
      "127    finer       boy  1      you thank\n",
      "128      boy  anywhere  1    youd people\n",
      "\n",
      "[129 rows x 4 columns]\n",
      "              Value  Count\n",
      "0       dursley mrs      2\n",
      "1       was dursley      2\n",
      "2         were they      2\n",
      "3           small a      1\n",
      "4    perfectly were      1\n",
      "..              ...    ...\n",
      "121     garden over      1\n",
      "122     four number      1\n",
      "123          firm a      1\n",
      "124        finer no      1\n",
      "125     youd people      1\n",
      "\n",
      "[126 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#input the example text\n",
    "import string\n",
    "import re\n",
    "text2 = pd.read_csv('harryPotter.txt', delimiter=' ', header=None)\n",
    "\n",
    "#removes all punctuations - preprocessing\n",
    "def remove_punctuation (input_str):\n",
    "    pattern = r'[!@#$%^&*()_+{}\\[\\]:;\"\\'`<>,.?/\\|\\\\-]'\n",
    "    cleaned = re.sub(pattern, '', input_str)\n",
    "    return cleaned\n",
    "\n",
    "text2=text2.T\n",
    "text2_strings = text2[0].astype(str).tolist()\n",
    "n_grams = []\n",
    "\n",
    "#mapper.py\n",
    "#create all pairs of 2 words - not unique yet. Append the value of 1. Generates intermediate key value pairs\n",
    "#force all strings to lowercase for comparison purposes.\n",
    "\n",
    "for i in range(len(text2_strings)-1):\n",
    "    row = [remove_punctuation(text2_strings[i].lower()), remove_punctuation(text2_strings[i+1].lower()), 1]\n",
    "    n_grams.append(row)\n",
    "\n",
    "#reducer.py\n",
    "n_gramdf = pd.DataFrame(n_grams)\n",
    "n_gramdf[3] = sorted(n_gramdf[1] + \" \" + n_gramdf[0])\n",
    "\n",
    "print(n_gramdf)\n",
    "\n",
    "#apply reduction on the third column, counting any duplicates\n",
    "count_series = n_gramdf[3].value_counts()\n",
    "count_df = count_series.reset_index()\n",
    "count_df.columns = ['Value', 'Count']\n",
    "\n",
    "print(count_df)\n",
    "\n",
    "#Example bash command to run the python files above using hadoop streaming\n",
    "#mapper.py and reducer.py would be separate files.\n",
    "\n",
    "#$HADOOP_HOME/bin/hadoop jar $HADOOP_HOME/hadoop-streaming.jar \\\n",
    "#-files assignment1_mapper.py,assignment1_reducer.p -mapper assignment1_mapper.py -reducer assignment1_reducer.p \\\n",
    "#-input harryPotter.txt -output output_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659a0074-d561-4517-b49a-b3c04368224d",
   "metadata": {},
   "source": [
    "#QUESTION 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b33f5ff6-1786-4160-93b9-3d0368947e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/nick/developer/ensf_612/assignment_1/harryPotter2.txt\n",
      "/Users/nick/developer/ensf_612/assignment_1/harryPotter.txt\n",
      "defaultdict(<class 'list'>, {'they': ['harryPotter2.txt', 'harryPotter.txt'], 'didnt': ['harryPotter2.txt', 'harryPotter.txt'], 'think': ['harryPotter2.txt'], 'could': ['harryPotter2.txt'], 'bear': ['harryPotter2.txt'], 'it': ['harryPotter2.txt'], 'if': ['harryPotter2.txt'], 'anyone': ['harryPotter2.txt'], 'found': ['harryPotter2.txt'], 'out': ['harryPotter2.txt'], 'about': ['harryPotter2.txt'], 'the': ['harryPotter2.txt', 'harryPotter.txt'], 'potters': ['harryPotter2.txt'], 'mrs': ['harryPotter2.txt', 'harryPotter.txt'], 'potter': ['harryPotter2.txt'], 'was': ['harryPotter2.txt', 'harryPotter.txt'], 'dursleys': ['harryPotter2.txt', 'harryPotter.txt'], 'sister': ['harryPotter2.txt'], 'but': ['harryPotter2.txt'], 'hadnt': ['harryPotter2.txt'], 'met': ['harryPotter2.txt'], 'for': ['harryPotter2.txt'], 'several': ['harryPotter2.txt'], 'years': ['harryPotter2.txt'], 'in': ['harryPotter2.txt', 'harryPotter.txt'], 'fact': ['harryPotter2.txt'], 'dursley': ['harryPotter2.txt', 'harryPotter.txt'], 'pretended': ['harryPotter2.txt'], 'she': ['harryPotter2.txt', 'harryPotter.txt'], 'have': ['harryPotter2.txt', 'harryPotter.txt'], 'a': ['harryPotter2.txt', 'harryPotter.txt'], 'because': ['harryPotter2.txt', 'harryPotter.txt'], 'her': ['harryPotter2.txt', 'harryPotter.txt'], 'and': ['harryPotter2.txt', 'harryPotter.txt'], 'goodfornothing': ['harryPotter2.txt'], 'husband': ['harryPotter2.txt'], 'were': ['harryPotter2.txt', 'harryPotter.txt'], 'as': ['harryPotter2.txt', 'harryPotter.txt'], 'undursleyish': ['harryPotter2.txt'], 'possible': ['harryPotter2.txt'], 'to': ['harryPotter2.txt', 'harryPotter.txt'], 'be': ['harryPotter2.txt', 'harryPotter.txt'], 'shuddered': ['harryPotter2.txt'], 'what': ['harryPotter2.txt'], 'neighbors': ['harryPotter2.txt', 'harryPotter.txt'], 'would': ['harryPotter2.txt'], 'say': ['harryPotter2.txt', 'harryPotter.txt'], 'arrived': ['harryPotter2.txt'], 'street': ['harryPotter2.txt'], 'knew': ['harryPotter2.txt'], 'that': ['harryPotter2.txt', 'harryPotter.txt'], 'had': ['harryPotter2.txt', 'harryPotter.txt'], 'small': ['harryPotter2.txt', 'harryPotter.txt'], 'son': ['harryPotter2.txt', 'harryPotter.txt'], 'too': ['harryPotter2.txt'], 'never': ['harryPotter2.txt'], 'even': ['harryPotter2.txt'], 'seen': ['harryPotter2.txt'], 'him': ['harryPotter2.txt'], 'this': ['harryPotter2.txt'], 'boy': ['harryPotter2.txt', 'harryPotter.txt'], 'another': ['harryPotter2.txt'], 'good': ['harryPotter2.txt'], 'reason': ['harryPotter2.txt'], 'keeping': ['harryPotter2.txt'], 'away': ['harryPotter2.txt'], 'want': ['harryPotter2.txt'], 'dudley': ['harryPotter2.txt', 'harryPotter.txt'], 'mixing': ['harryPotter2.txt'], 'with': ['harryPotter2.txt', 'harryPotter.txt'], 'child': ['harryPotter2.txt'], 'like': ['harryPotter2.txt'], 'when': ['harryPotter2.txt'], 'mr': ['harryPotter2.txt', 'harryPotter.txt'], 'woke': ['harryPotter2.txt'], 'up': ['harryPotter2.txt'], 'on': ['harryPotter2.txt', 'harryPotter.txt'], 'dull': ['harryPotter2.txt'], 'gray': ['harryPotter2.txt'], 'tuesday': ['harryPotter2.txt'], 'our': ['harryPotter2.txt'], 'story': ['harryPotter2.txt'], 'starts': ['harryPotter2.txt'], 'there': ['harryPotter2.txt', 'harryPotter.txt'], 'nothing': ['harryPotter2.txt'], 'cloudy': ['harryPotter2.txt'], 'sky': ['harryPotter2.txt'], 'outside': ['harryPotter2.txt'], 'suggest': ['harryPotter2.txt'], 'strange': ['harryPotter2.txt', 'harryPotter.txt'], 'mysterious': ['harryPotter2.txt', 'harryPotter.txt'], 'things': ['harryPotter2.txt'], 'soon': ['harryPotter2.txt'], 'happening': ['harryPotter2.txt'], 'all': ['harryPotter2.txt'], 'over': ['harryPotter2.txt', 'harryPotter.txt'], 'country': ['harryPotter2.txt'], 'hummed': ['harryPotter2.txt'], 'he': ['harryPotter2.txt', 'harryPotter.txt'], 'picked': ['harryPotter2.txt'], 'his': ['harryPotter2.txt'], 'most': ['harryPotter2.txt'], 'boring': ['harryPotter2.txt'], 'tie': ['harryPotter2.txt'], 'work': ['harryPotter2.txt'], 'gossiped': ['harryPotter2.txt'], 'happily': ['harryPotter2.txt'], 'wrestled': ['harryPotter2.txt'], 'screaming': ['harryPotter2.txt'], 'into': ['harryPotter2.txt'], 'high': ['harryPotter2.txt'], 'chair': ['harryPotter2.txt'], 'nan': ['harryPotter2.txt'], 'of': ['harryPotter2.txt', 'harryPotter.txt'], 'them': ['harryPotter2.txt'], 'noticed': ['harryPotter2.txt'], 'large': ['harryPotter2.txt', 'harryPotter.txt'], 'tawny': ['harryPotter2.txt'], 'owl': ['harryPotter2.txt'], 'flutter': ['harryPotter2.txt'], 'past': ['harryPotter2.txt'], 'window': ['harryPotter2.txt'], 'at': ['harryPotter2.txt'], 'half': ['harryPotter2.txt'], 'eight': ['harryPotter2.txt'], 'briefcase': ['harryPotter2.txt'], 'pecked': ['harryPotter2.txt'], 'cheek': ['harryPotter2.txt'], 'tried': ['harryPotter2.txt'], 'kiss': ['harryPotter2.txt'], 'goodbye': ['harryPotter2.txt'], 'missed': ['harryPotter2.txt'], 'now': ['harryPotter2.txt'], 'having': ['harryPotter2.txt'], 'tantrum': ['harryPotter2.txt'], 'throwing': ['harryPotter2.txt'], 'cereal': ['harryPotter2.txt'], 'walls': ['harryPotter2.txt'], '“little': ['harryPotter2.txt'], 'tyke”': ['harryPotter2.txt'], 'chortled': ['harryPotter2.txt'], 'left': ['harryPotter2.txt'], 'house': ['harryPotter2.txt'], 'got': ['harryPotter2.txt'], 'car': ['harryPotter2.txt'], 'backed': ['harryPotter2.txt'], 'number': ['harryPotter2.txt', 'harryPotter.txt'], 'fours': ['harryPotter2.txt'], 'drive': ['harryPotter2.txt', 'harryPotter.txt'], 'four': ['harryPotter.txt'], 'privet': ['harryPotter.txt'], 'proud': ['harryPotter.txt'], 'perfectly': ['harryPotter.txt'], 'normal': ['harryPotter.txt'], 'thank': ['harryPotter.txt'], 'you': ['harryPotter.txt'], 'very': ['harryPotter.txt'], 'much': ['harryPotter.txt'], 'last': ['harryPotter.txt'], 'people': ['harryPotter.txt'], 'youd': ['harryPotter.txt'], 'expect': ['harryPotter.txt'], 'involved': ['harryPotter.txt'], 'anything': ['harryPotter.txt'], 'or': ['harryPotter.txt'], 'just': ['harryPotter.txt'], 'hold': ['harryPotter.txt'], 'such': ['harryPotter.txt'], 'nonsense': ['harryPotter.txt'], 'director': ['harryPotter.txt'], 'firm': ['harryPotter.txt'], 'called': ['harryPotter.txt'], 'grunnings': ['harryPotter.txt'], 'which': ['harryPotter.txt'], 'made': ['harryPotter.txt'], 'drills': ['harryPotter.txt'], 'big': ['harryPotter.txt'], 'beefy': ['harryPotter.txt'], 'man': ['harryPotter.txt'], 'hardly': ['harryPotter.txt'], 'any': ['harryPotter.txt'], 'neck': ['harryPotter.txt'], 'although': ['harryPotter.txt'], 'did': ['harryPotter.txt'], 'mustache': ['harryPotter.txt'], 'thin': ['harryPotter.txt'], 'blonde': ['harryPotter.txt'], 'nearly': ['harryPotter.txt'], 'twice': ['harryPotter.txt'], 'usual': ['harryPotter.txt'], 'amount': ['harryPotter.txt'], 'came': ['harryPotter.txt'], 'useful': ['harryPotter.txt'], 'spent': ['harryPotter.txt'], 'so': ['harryPotter.txt'], 'time': ['harryPotter.txt'], 'craning': ['harryPotter.txt'], 'garden': ['harryPotter.txt'], 'fences': ['harryPotter.txt'], 'spying': ['harryPotter.txt'], 'their': ['harryPotter.txt'], 'opinion': ['harryPotter.txt'], 'no': ['harryPotter.txt'], 'finer': ['harryPotter.txt'], 'anywhere': ['harryPotter.txt']})\n"
     ]
    }
   ],
   "source": [
    "#input the example text\n",
    "import string\n",
    "import re\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "# Directory with all .txt files\n",
    "csv_directory = '/Users/nick/developer/ensf_612/assignment_1'\n",
    "\n",
    "#key value pairs will be a list of dictionaries, storing the unique words along with the filename\n",
    "kv_pairs = []\n",
    "\n",
    "# finds all .txt files in the current directory, and reads all words in each file.\n",
    "for filename in os.listdir(csv_directory):\n",
    "    if filename.endswith('.txt'):\n",
    "        \n",
    "        dic={}\n",
    "        \n",
    "        # Construct the full file path of each file in the directory\n",
    "        file_path = os.path.join(csv_directory, filename)\n",
    "        print(file_path)\n",
    "        \n",
    "        #read each file in\n",
    "        df = pd.read_csv(file_path, delimiter=' ', header=None)\n",
    "        \n",
    "        #for each word in the current file: remove all punctuation, and append it to a dictionary\n",
    "        #with the filename that it was found in as the value\n",
    "        #since it's in a dictionary, there will only be unique key's allowed. \n",
    "        #force all to lowercase for comparison purposes.\n",
    "        \n",
    "        for i in df:\n",
    "            #mapper.py - map each unique word in the current file, with value as the filename.\n",
    "            dic[remove_punctuation(str(df[i].tolist())).lower()] = filename\n",
    "        \n",
    "        \n",
    "        #append the current dictionary to the list of dictionaries. One dictionary per file read.\n",
    "        kv_pairs.append(dic)\n",
    "        \n",
    "#reducer.py - need to combine along the value. If two files have the same unique word, combine the file names.\n",
    "combined = defaultdict(list)\n",
    "\n",
    "for i in (kv_pairs[0], kv_pairs[1]):\n",
    "    for key, value in i.items():\n",
    "        combined[key].append(value)\n",
    "print(combined)\n",
    "        \n",
    "        \n",
    "#removes all punctuations\n",
    "def remove_punctuation (input_str):\n",
    "    pattern = r'[!@#$%^&*()_+{}\\[\\]:;\"\\'’`<>,.?/\\|\\\\-]'\n",
    "    cleaned = re.sub(pattern, '', input_str)\n",
    "    return cleaned\n",
    "\n",
    "\n",
    "\n",
    "#Example bash command to run the python files above using hadoop streaming\n",
    "#mapper.py and reducer.py would be separate files.\n",
    "\n",
    "#$HADOOP_HOME/bin/hadoop jar $HADOOP_HOME/hadoop-streaming.jar \\\n",
    "#-files assignment1_mapper.py,assignment1_reducer.p -mapper assignment1_mapper.py -reducer assignment1_reducer.p \\\n",
    "#-input harryPotter.txt -output output_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b056adc7-d4db-44b2-8f65-57a9d02e29fc",
   "metadata": {},
   "source": [
    "#QUESTION 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c9078a01-84ec-4eb2-97a8-c7a9c0a4bb93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'a', 'a', 'a', 'although', 'amount', 'and', 'and', 'and', 'and', 'any', 'anything', 'anywhere', 'as', 'be', 'because', 'beefy', 'big', 'blonde', 'boy', 'called', 'called', 'came', 'craning', 'did', 'didnt', 'director', 'drills', 'drive', 'dudley', 'dursley', 'dursley', 'dursley', 'dursleys', 'expect', 'fences', 'finer', 'firm', 'four', 'garden', 'grunnings', 'had', 'had', 'hardly', 'have', 'he', 'he', 'her', 'hold', 'in', 'in', 'in', 'involved', 'just', 'large', 'last', 'made', 'man', 'mr', 'mr', 'mrs', 'mrs', 'much', 'much', 'mustache', 'mysterious', 'nearly', 'neck', 'neck', 'neighbors', 'no', 'nonsense', 'normal', 'number', 'of', 'of', 'of', 'of', 'on', 'opinion', 'or', 'over', 'people', 'perfectly', 'privet', 'proud', 'say', 'she', 'small', 'so', 'son', 'spent', 'spying', 'strange', 'such', 'thank', 'that', 'the', 'the', 'the', 'the', 'the', 'their', 'there', 'they', 'they', 'they', 'thin', 'time', 'to', 'to', 'twice', 'useful', 'usual', 'very', 'very', 'very', 'was', 'was', 'was', 'was', 'were', 'were', 'were', 'which', 'which', 'with', 'with', 'you', 'youd']\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import re\n",
    "\n",
    "file_path = 'harryPotter.txt'\n",
    "text4 = pd.read_csv(file_path, delimiter=' ', header=None)\n",
    "\n",
    "#removes all punctuations - preprocessing\n",
    "def remove_punctuation (input_str):\n",
    "    pattern = r'[!@#$%^&*()_+{}\\[\\]:;\"\\'’`<>,.?/\\|\\\\-]'\n",
    "    cleaned = re.sub(pattern, '', input_str)\n",
    "    return cleaned\n",
    "\n",
    "text4=text4.T\n",
    "text4_strings = text4[0].astype(str).tolist()\n",
    "\n",
    "#create list of characters of the first half and second half of the alphabet - use in reducers\n",
    "\n",
    "#Specify each reducer cover one half of the alphabet, ordered by first letter of the string\n",
    "#this is NOT optimal, since the first half of the alphabet is much more popular. Words that start with characters W, X, Y, Z are uncommon.\n",
    "#another method can be to have 26 reducers - one reducer for each character, this will modify the reducing stage slightly.\n",
    "\n",
    "first_half = string.ascii_lowercase[:len(string.ascii_lowercase)//2]\n",
    "second_half = string.ascii_lowercase[len(string.ascii_lowercase)//2:]\n",
    "\n",
    "kv_pairs = []\n",
    "\n",
    "#MAPPING - format in K1.K2:V\n",
    "#K1 = which reducer should manage it\n",
    "#K2 = remainder of the word\n",
    "#V = null\n",
    "\n",
    "for i in text4_strings:\n",
    "    row = []\n",
    "    #preprocessing step - remove all punctuation and force to lowercase\n",
    "    i = remove_punctuation(i.lower())\n",
    "    \n",
    "    #append the correct primary key which signifies which reducer will manage the word.\n",
    "    if i[0] in first_half:\n",
    "        row = [1, i, None]\n",
    "    if i[0] in second_half:\n",
    "        row = [2, i, None]\n",
    "    \n",
    "    kv_pairs.append(row)\n",
    "\n",
    "\n",
    "#send to appropriate reducers\n",
    "reducer1_pairs = []\n",
    "reducer2_pairs = []\n",
    "for i in kv_pairs:\n",
    "    if i[0] == 1:\n",
    "        reducer1_pairs.append(i)\n",
    "    if i[0] == 2:\n",
    "        reducer2_pairs.append(i)\n",
    "        \n",
    "#reducer1 - first half of alphabet\n",
    "ordered = []\n",
    "for i in reducer1_pairs:\n",
    "    #append the entire word to the ordered list\n",
    "    ordered.append(i[1])\n",
    "    \n",
    "for i in reducer2_pairs:\n",
    "    #append the entire word to the ordered list\n",
    "    ordered.append(i[1])\n",
    "    \n",
    "ordered = sorted(ordered)\n",
    "\n",
    "print(ordered)\n",
    "    \n",
    "\n",
    "#example command to call hadoop map reducer using multiple keys, field separator = ','\n",
    "\n",
    "#$HADOOP_HOME/bin/hadoop jar $HADOOP_HOME/hadoop-streaming.jar \\\n",
    "#-D stream.map.output.field.separator=, \\\n",
    "#-D stream.num.map.output.key.fields=3 \\\n",
    "#-D map.output.key.field.separator=, \\\n",
    "#-D mapred.text.key.partitioner.options=-k1,2 \\\n",
    "#-D mapred.reduce.tasks=12 \\\n",
    "#-input myInputDirs \\\n",
    "#-output myOutputDir \\\n",
    "#-mapper org.apache.hadoop.mapred.lib.IdentityMapper \\\n",
    "#-reducer org.apache.hadoop.mapred.lib.IdentityReducer \\\n",
    "#-partitioner org.apache.hadoop.mapred.lib.KeyFieldBasedPartitioner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f312483-9351-4dbf-903e-9505571d3b39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
